# -*- coding: utf-8 -*-
"""Aula 11 - Data Science exercício

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cp3Y7pE25gndq6hz5786NbzmfZn9pmDX

<hr style="height:10px">

<div class='container2'>
	<div>
		<img src='images/car_header.png' ALIGN='left' style='width:10em'>
	</div>
	<div style='padding: 0 7em 2em 12em;'>
	<h1>Laboratório de Inovação e Automação 1 (LIA 1)</h1>
	<div style="font-size:12pt;float:left;"> 2025/2 | 46M34 | Sala 200 CAE</div><br><br>
    <div style="font-size:12pt;float:left;"><b>Projetos de Inteligência Artificial - Análise Exploratória de Dados </b></div>
	</div>
</div>

<hr style="height:5px">

<h2>Aula 11 - Data Science - Análise de Dados de Carros - <a href="https://www.kaggle.com/datasets/elikplim/car-evaluation-data-set?resource=download">Car Evaluation Dataset</a> </h2>

Notebook desenvolvido por:  Vitor Hugo ALves Macedo</a>

<hr style="height:2px">

1. Bibliotecas Necessárias
"""

# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

print("Bibliotecas carregadas com sucesso!")

"""2. Carregar e Exibir os Dados da Fonte"""

# Importar a base de dados
column_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']
df_car = pd.read_csv('/content/car_evaluation.csv', header=None, names=column_names)

# Exibir amostra
display(df_car.head())

# Informações gerais
df_car.info()

"""3. Pré-processamento
3.1 Eliminação de atributos irrelevantes

(Nesse dataset não há atributos como id, então nada a remover.)

3.2 Tratamento de atributos com valores ausentes
"""

print("Valores ausentes por coluna:\n", df_car.isnull().sum())

# If there were null values in "doors", we would replace them with the most frequent value
# df_car['doors'] = df_car['doors'].fillna(df_car['doors'].mode()[0])

"""3.3 Tratamento de duplicatas"""

def delDuplicatas(df):
    df = df.drop_duplicates(keep='first')
    return df

df_car = delDuplicatas(df_car)

"""3.4 Tratamento de inconsistências

⚠️ Como o dataset é categórico, inconsistências seriam registros idênticos mas com classes diferentes.
"""

df_duplicates = df_car[df_car.duplicated(subset=['buying','maint','doors','persons','lug_boot','safety'], keep=False)]

if len(df_duplicates)>0:
    print("Objetos inconsistentes encontrados!")
    display(df_duplicates)
    # Remover inconsistências
    df_car = df_car.drop_duplicates(subset=['buying','maint','doors','persons','lug_boot','safety'], keep=False)
else:
    print("Não existem inconsistências!")

"""3.5 Codificação de variáveis categóricas"""

df_encoded = pd.get_dummies(df_car, drop_first=True)
display(df_encoded.head())

"""3.6 Detecção e tratamento de outliers

Como todos os atributos são categóricos, não há outliers numéricos a remover.

4. Análise dos Dados \
4.1 Estatísticas da base

---
"""

display(df_car.describe(include='all'))

"""4.2 Distribuição da classe"""

sns.countplot(data=df_car, x='class')
plt.title("Distribuição das Classes")
plt.show()

"""4.3 Segurança x Classe"""

sns.countplot(data=df_car, x='safety', hue='class')
plt.title("Segurança x Classe")
plt.show()

"""4.4 Capacidade de pessoas x Classe"""

sns.countplot(data=df_car, x='persons', hue='class')
plt.title("Capacidade de Pessoas x Classe")
plt.show()

"""5. Predição\
5.1 Separar variáveis
"""

X = df_encoded.drop(columns=['class_unacc'])  # manter todas variáveis preditoras
y = df_car['class']

"""5.2 Treino e teste"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

"""5.3 Treinamento"""

from sklearn.ensemble import RandomForestClassifier

modelo = RandomForestClassifier(n_estimators=100, random_state=42)
modelo.fit(X_train, y_train)

"""5.4 Avaliação"""

from sklearn.metrics import accuracy_score, classification_report

y_pred = modelo.predict(X_test)

print("Acurácia:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
